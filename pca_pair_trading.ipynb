{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA-Based Statistical Arbitrage (Pair Trading)\n",
    "\n",
    "## Project Overview\n",
    "This project demonstrates a **Statistical Arbitrage** strategy using **Principal Component Analysis (PCA)** to identify trading pairs.\n",
    "\n",
    "### The Strategy\n",
    "1.  **Dimensionality Reduction**: We use PCA to extract the latent \"market factors\" driving stock returns.\n",
    "2.  **Residual Analysis**: We isolate the *idiosyncratic* component of each stock's return (the part NOT explained by the market).\n",
    "3.  **Pair Selection**: We find stocks with highly correlated residuals. These stocks behave similarly after removing market risk, making them ideal candidates for mean-reversion trading.\n",
    "4.  **Trading**: We calculate the Z-Score of the spread between the pair and trade when it diverges significantly from the mean.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Simulation\n",
    "To ensure the strategy logic is sound and reproducible without external API keys, we simulate a market environment.\n",
    "\n",
    "We generate **50 stocks** driven by **3 latent factors** (e.g., Market, Tech Sector, Energy Sector) plus some random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_days = 500\n",
    "n_stocks = 50\n",
    "n_factors = 3\n",
    "\n",
    "# 1. Generate Latent Factors (Random Walks)\n",
    "factors = np.random.normal(0, 1, (n_days, n_factors))\n",
    "factors = np.cumsum(factors, axis=0) # Make them trend\n",
    "\n",
    "# 2. Generate Factor Loadings (How much each stock depends on factors)\n",
    "# Some stocks correlate positively, some negatively\n",
    "loadings = np.random.normal(0, 1, (n_factors, n_stocks))\n",
    "\n",
    "# 3. Generate Idiosyncratic Noise (Specific to each stock)\n",
    "noise = np.random.normal(0, 0.5, (n_days, n_stocks))\n",
    "\n",
    "# 4. Construct Stock Prices\n",
    "# Returns = Factors * Loadings + Noise\n",
    "# We'll simulate returns first, then convert to prices\n",
    "factor_returns = np.random.normal(0, 0.01, (n_days, n_factors))\n",
    "stock_returns = np.dot(factor_returns, loadings) + np.random.normal(0, 0.005, (n_days, n_stocks))\n",
    "\n",
    "# Create DataFrame\n",
    "dates = pd.date_range(start='2023-01-01', periods=n_days, freq='B')\n",
    "returns_df = pd.DataFrame(stock_returns, index=dates, columns=[f'Stock_{i}' for i in range(n_stocks)])\n",
    "\n",
    "# Calculate Prices (starting at 100)\n",
    "prices_df = 100 * (1 + returns_df).cumprod()\n",
    "\n",
    "print(\"Simulated Data Shape:\", prices_df.shape)\n",
    "prices_df.plot(legend=False, alpha=0.3, color='grey', title='Simulated Stock Universe (50 Stocks)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA for Factor Extraction\n",
    "We use PCA to identify the common drivers of returns. By removing these, we can focus on the *residuals*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize returns before PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_returns = scaler.fit_transform(returns_df)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA(n_components=10) # Let's look at top 10 components\n",
    "pca.fit(scaled_returns)\n",
    "\n",
    "# Plot Explained Variance (Scree Plot)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(1, 11), pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, 11), np.cumsum(pca.explained_variance_ratio_), marker='o', color='red')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA Scree Plot')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top 3 Components explain {np.sum(pca.explained_variance_ratio_[:3])*100:.2f}% of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Residual Analysis & Pair Selection\n",
    "We reconstruct the returns using only the top 3 components (the \"Market\"). \n",
    "Then, `Actual Returns - Market Returns = Residuals`.\n",
    "\n",
    "Stocks with highly correlated **residuals** are good pairs because they move together *independent* of the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the Market Component (Common Factors)\n",
    "n_components_selected = 3\n",
    "pca_selected = PCA(n_components=n_components_selected)\n",
    "factors_latent = pca_selected.fit_transform(scaled_returns)\n",
    "loadings_latent = pca_selected.components_\n",
    "\n",
    "# Reconstruct the \"Common Return\" part\n",
    "common_returns = np.dot(factors_latent, loadings_latent)\n",
    "\n",
    "# 2. Calculate Residuals (Idiosyncratic Returns)\n",
    "# Scale back to original magnitude for easier interpretation\n",
    "residuals = scaled_returns - common_returns\n",
    "\n",
    "# 3. Find the Best Pair (Highest Correlation of Residuals)\n",
    "corr_matrix = np.corrcoef(residuals.T)\n",
    "np.fill_diagonal(corr_matrix, -1) # Ignore self-correlation\n",
    "\n",
    "# Find indices of max correlation\n",
    "max_corr = np.max(corr_matrix)\n",
    "stock_a_idx, stock_b_idx = np.unravel_index(np.argmax(corr_matrix), corr_matrix.shape)\n",
    "\n",
    "stock_a = returns_df.columns[stock_a_idx]\n",
    "stock_b = returns_df.columns[stock_b_idx]\n",
    "\n",
    "print(f\"Best Pair Found: {stock_a} & {stock_b}\")\n",
    "print(f\"Residual Correlation: {max_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Strategy Backtest\n",
    "Now we trade the spread between these two stocks.\n",
    "\n",
    "**Logic:**\n",
    "1.  Calculate the **Spread**: `Price_A / Price_B` (or log price difference).\n",
    "2.  Calculate **Z-Score**: `(Spread - Mean) / StdDev` (rolling window).\n",
    "3.  **Signal**:\n",
    "    *   Z-Score > 2: Short A / Long B (Spread is too high, expect reversion).\n",
    "    *   Z-Score < -2: Long A / Short B (Spread is too low, expect reversion).\n",
    "    *   Z-Score crosses 0: Exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construct the Spread\n",
    "s1 = prices_df[stock_a]\n",
    "s2 = prices_df[stock_b]\n",
    "\n",
    "# Hedge Ratio (OLS)\n",
    "import statsmodels.api as sm\n",
    "model = sm.OLS(s1, sm.add_constant(s2))\n",
    "results = model.fit()\n",
    "hedge_ratio = results.params[stock_b]\n",
    "\n",
    "spread = s1 - hedge_ratio * s2\n",
    "\n",
    "# 2. Calculate Z-Score (Rolling)\n",
    "window = 20\n",
    "rolling_mean = spread.rolling(window).mean()\n",
    "rolling_std = spread.rolling(window).std()\n",
    "z_score = (spread - rolling_mean) / rolling_std\n",
    "\n",
    "# 3. Generate Signals\n",
    "entry_threshold = 2.0\n",
    "exit_threshold = 0.0\n",
    "\n",
    "long_signal = (z_score < -entry_threshold)\n",
    "short_signal = (z_score > entry_threshold)\n",
    "exit_signal = (np.abs(z_score) < 0.5) # Exit when close to mean\n",
    "\n",
    "positions = pd.DataFrame(index=spread.index, columns=['Stock_A', 'Stock_B']).fillna(0)\n",
    "current_position = 0 # 0: Flat, 1: Long Spread, -1: Short Spread\n",
    "\n",
    "for i in range(len(spread)):\n",
    "    if current_position == 0:\n",
    "        if long_signal.iloc[i]:\n",
    "            current_position = 1 # Long A, Short B\n",
    "        elif short_signal.iloc[i]:\n",
    "            current_position = -1 # Short A, Long B\n",
    "    elif current_position == 1:\n",
    "        if z_score.iloc[i] > -0.5: # Exit condition\n",
    "            current_position = 0\n",
    "    elif current_position == -1:\n",
    "        if z_score.iloc[i] < 0.5: # Exit condition\n",
    "            current_position = 0\n",
    "            \n",
    "    positions.iloc[i]['Stock_A'] = current_position\n",
    "    positions.iloc[i]['Stock_B'] = -current_position * hedge_ratio\n",
    "\n",
    "# 4. Calculate PnL\n",
    "daily_pnl = (positions.shift(1)['Stock_A'] * returns_df[stock_a]) + (positions.shift(1)['Stock_B'] * returns_df[stock_b])\n",
    "cumulative_pnl = (1 + daily_pnl).cumprod()\n",
    "\n",
    "# Plot Results\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "ax[0].plot(spread, label='Spread')\n",
    "ax[0].plot(rolling_mean, 'r--', label='Rolling Mean')\n",
    "ax[0].set_title(f'Pair Spread: {stock_a} vs {stock_b}')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(cumulative_pnl, color='green', label='Strategy Equity Curve')\n",
    "ax[1].set_title('Cumulative Strategy Returns')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sharpe = (daily_pnl.mean() / daily_pnl.std()) * np.sqrt(252)\n",
    "print(f\"Strategy Sharpe Ratio: {sharpe:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
